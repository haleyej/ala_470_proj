{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surprised-alert",
   "metadata": {},
   "source": [
    "<h1>ALA 470 Final Project</h1>\n",
    "</br>\n",
    "By Haley Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "settled-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-shield",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operating-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fake.csv\")\n",
    "df_2 = pd.read_csv(\"news_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-constitutional",
   "metadata": {},
   "source": [
    "<h2>Clean Up</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seasonal-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT IF YOU WANT TO USE BOTH FILES\n",
    "# df_1['title'] = df_1['title'].str.lower()\n",
    "# df_1['author'] = df_1['author'].str.lower()\n",
    "\n",
    "# df_1 = df_1.drop(columns = {'language', 'site_url', 'main_img_url', 'type', 'published', 'text'}, axis = 1)\n",
    "\n",
    "# df_2['title'] = df_2['title'].str.lower()\n",
    "# df_2['author'] = df_2['author'].str.lower()\n",
    "\n",
    "# df = df_1.merge(df_2, on = ['title', 'author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-idaho",
   "metadata": {},
   "source": [
    "<h2>NLTK</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "junior-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'ord_in_thread', 'author', 'published', 'title', 'text',\n",
       "       'language', 'crawled', 'site_url', 'country', 'domain_rank',\n",
       "       'thread_title', 'spam_score', 'main_img_url', 'replies_count',\n",
       "       'participants_count', 'likes', 'comments', 'shares', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-orlando",
   "metadata": {},
   "source": [
    "<h3>Tokenize</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statutory-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_normalized'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coupled-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['text_normalized'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hairy-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "df['non_stopwords'] = df['words'].apply(lambda x: [w for w in x if w not in stop_words])\n",
    "df['non_stopwords_count'] = df['non_stopwords'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-reggae",
   "metadata": {},
   "source": [
    "<h3>Named Entity Recognition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_people(s):\n",
    "    people = []\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    entities = nltk.chunk.ne_chunk(tagged)\n",
    "\n",
    "    for entity in entities.subtrees():\n",
    "        if entity.label() == \"PERSON\":\n",
    "            name = []\n",
    "            for leaf in entity.leaves():\n",
    "                name.append(leaf[0])\n",
    "            people.append(\" \".join(name))\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Persons'] = df['text_normalized'].apply(get_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-batch",
   "metadata": {},
   "source": [
    "<h2>Plotting Tokens</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "endangered-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = list(df['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = []\n",
    "for i in range(len(types)):\n",
    "    matches = df[df['type'] == types[i]]\n",
    "    exploded_tokens = df.explode('non_stopwords')\n",
    "    exploded_tokens = exploded_tokens[pd.isnull(exploded_tokens['non_stopwords']) == False]\n",
    "    top_tokens.append(exploded_tokens['non_stopwords'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-soundtrack",
   "metadata": {},
   "source": [
    "<h2>Visualize</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = []\n",
    "for i in range(len(types)):\n",
    "    matches = df[df['type'] == types[i]]\n",
    "    exploded = matches.explode('Persons')\n",
    "    exploded = exploded[pd.isnull(exploded['Persons']) == False]\n",
    "    top.append(exploded['Persons'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = top[2]\n",
    "top = top[:2] + top[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4)\n",
    "fig.set_size_inches(25, 10)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 7:\n",
    "        break\n",
    "    t = types[i]\n",
    "    grid = sns.barplot(x = top[i].values, y = top[i].index, ax = ax)\n",
    "    grid.set(ylabel = t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "top[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-executive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
